<!DOCTYPE html>
<html>
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <!-- Metadata, OpenGraph and Schema.org -->




<!-- Standard metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<title>
  
  
    
      Equivariant Neural Fields - continuous representations grounded in geometry |  
    
  
</title>
<meta name="author" content=" ">
<meta name="description" content="An intro to geometry-grounded continuous signal representations and their use in modelling spatio-temporal dynamics.">

  <meta name="keywords" content="geometry, machine-learning, generative-models, deep-learning, representation-learning">










<!-- Bootstrap & MDB -->
<link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

<!-- Bootstrap Table -->


<!-- Fonts & Icons -->
<link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5">
<link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap">

<!-- Code Syntax Highlighting -->
<link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light">



<!-- Styles -->

<!-- pseudocode -->



  <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">

<link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e">
<link rel="canonical" href="http://localhost:4000/blog/2024/equivariant-neural-fields/">

<!-- Dark Mode -->
<script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script>

  <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark">
  <script>
    initTheme();
  </script>


<!-- GeoJSON support via Leaflet -->


<!-- diff2html -->






    
      <!-- Medium Zoom JS -->
      <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script>
      <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script>
    
    <!-- jQuery -->
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    
  
    <!-- MathJax -->
    <script type="text/javascript">
      window.MathJax = {
        tex: {
          tags: 'ams',
        },
      };
    </script>
    <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js"></script>
    <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  


    <!-- Distill js -->
    <script src="/assets/js/distillpub/template.v2.js"></script>
    <script src="/assets/js/distillpub/transforms.v2.js"></script>
    <script src="/assets/js/distillpub/overrides.js"></script>
    
      <!-- Page/Post style -->
      <style type="text/css">
        .fake-img {
  background: #bbb;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
  margin-bottom: 12px;
} .fake-img p {
  font-family: monospace;
  color: white;
  text-align: left;
  margin: 12px 0;
  text-align: center;
  font-size: 16px;
}

      </style>
    
  </head>

  <body>
<d-front-matter>
    <script async type="text/json">
      {
            "title": "Equivariant Neural Fields - continuous representations grounded in geometry",
            "description": "An intro to geometry-grounded continuous signal representations and their use in modelling spatio-temporal dynamics.",
            "published": "June 01, 2024",
            "authors": [
              
              {
                "author": "David R. Wessels*",
                "authorURL": "https://www.linkedin.com/in/david-wessels-b24299122/?originalSubdomain=nl",
                "affiliations": [
                  {
                    "name": "University of Amsterdam",
                    "url": ""
                  }
                ]
              },
              
              {
                "author": "David M. Knigge*",
                "authorURL": "https://davidmknigge.nl",
                "affiliations": [
                  {
                    "name": "University of Amsterdam",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script>
  </d-front-matter>

  
    <!-- Header -->
    <header>
  <!-- Nav Bar -->
  <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation">
    <div class="container">
      
        <a class="navbar-brand title font-weight-lighter" href="/">
          
            
            
            
          
        </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>

      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          

          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">about
              
            </a>
          </li>

          <!-- Other pages -->
          
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
              
                <li class="nav-item ">
                  
                  <a class="nav-link" href="/instructions/">instructions
                    
                  </a>
                </li>
              
            
          
          
            <!-- Toogle theme mode -->
            <li class="toggle-container">
              <button id="light-toggle" title="Change theme">
                <i class="ti ti-sun-moon" id="light-toggle-system"></i>
                <i class="ti ti-moon-filled" id="light-toggle-dark"></i>
                <i class="ti ti-sun-filled" id="light-toggle-light"></i>
              </button>
            </li>
          
        </ul>
      </div>
    </div>
  </nav>
  
    <!-- Scrolling Progress Bar -->
    <progress id="progress" value="0">
      <div class="progress-container">
        <span class="progress-bar"></span>
      </div>
    </progress>
  
</header>


    <!-- Content -->
    <div class="post distill">
      <d-title>
        <h1>Equivariant Neural Fields - continuous representations grounded in geometry</h1>
        <p>An intro to geometry-grounded continuous signal representations and their use in modelling spatio-temporal dynamics.</p>
      </d-title>
      
        <d-byline></d-byline>
      

      <d-article>
        
          <d-contents>
            <nav class="l-text figcaption">
              <h3>Contents</h3>
              
                <div>
                  <a href="#introduction">Introduction</a>
                </div>
                
                  <ul>
                    
                      <li>
                        <a href="#the-evolution-of-neural-fields">The Evolution of Neural Fields</a>
                      </li>
                    
                      <li>
                        <a href="#introducing-equivariant-neural-fields">Introducing Equivariant Neural Fields</a>
                      </li>
                    
                      <li>
                        <a href="#key-properties-of-enfs">Key Properties of ENFs</a>
                      </li>
                    
                      <li>
                        <a href="#use-of-neural-fields-in-downstream-tasks">Use of Neural Fields in downstream tasks</a>
                      </li>
                    
                  </ul>
                
              
                <div>
                  <a href="#methodology">Methodology</a>
                </div>
                
                  <ul>
                    
                      <li>
                        <a href="#requirements-for-equivariant-neural-fields">Requirements for Equivariant Neural Fields</a>
                      </li>
                    
                      <li>
                        <a href="#equivariance-through-bi-invariant-cross-attention">Equivariance through Bi-invariant Cross-Attention</a>
                      </li>
                    
                      <li>
                        <a href="#enforcing-locality-in-equivariant-neural-fields">Enforcing Locality in Equivariant Neural Fields</a>
                      </li>
                    
                  </ul>
                
              
                <div>
                  <a href="#experimental-validation">Experimental Validation</a>
                </div>
                
                  <ul>
                    
                      <li>
                        <a href="#image-and-shape-reconstruction-and-classification">Image and Shape Reconstruction and Classification</a>
                      </li>
                    
                      <li>
                        <a href="#latent-space-editing">Latent Space Editing</a>
                      </li>
                    
                      <li>
                        <a href="#spatiotemporal-dynamics-modelling">Spatiotemporal Dynamics Modelling</a>
                      </li>
                    
                  </ul>
                
              
                <div>
                  <a href="#conclusion">Conclusion</a>
                </div>
                
              
            </nav>
          </d-contents>
        
        <h2 id="introduction">Introduction</h2>
<p>Neural fields (NeFs) <d-cite key="xie2022neural"></d-cite> have emerged as a promising paradigm for representing continuous signals in a variety of domains. 
Recently, they have been used as a continuous alternative for classical discrete signal representations - showing promising results especially in higher dimensional settings where traditional grid-based methods often fall short <d-cite key="dupont2022data"></d-cite>.</p>

<p>A major limitation of NeFs as representation is their lack of interpretibility and preservation of geometric information. In this blog post, we delve into the recent advancements presented in the paper “Grounding Continuous Representations in Geometry: Equivariant Neural Fields” <d-cite key="wessels2024ENF"></d-cite>, and explore how Equivariant Neural Fields (ENFs) enhance the capabilities of NeFs through geometric grounding and equivariance properties. We then elaborate upon their use as a representation by discussing the paper “Space-Time Continuous PDE Forecasting using Equivariant Neural Fields” <d-cite key="knigge2024pde"></d-cite>, which demonstrates the use of ENFs in modelling spatiotemporal dynamics. An important upcomming field of research, in which the geometric grounding of NeFs is crucial.</p>

<h3 id="the-evolution-of-neural-fields">The Evolution of Neural Fields</h3>

<p>Neural fields are functions that map spatial coordinates to feature representations. For instance, a neural field \(f_{\theta}: \mathbb{R}^d \rightarrow \mathbb{R}^c\) can map pixel coordinates \(x\) to RGB values to represent images. These fields are typically parameterized by neural networks, which are optimized to approximate a target signal \(f_\theta\) within a reconstruction task. Although this gives rise to continuous representations, for multiple signals, the weights \(\theta_f\) are optimized separately for each signal \(f\), leading to a lack of shared structure across different signals and the need to train different seperate models.</p>

<p>Neural fields are functions that map spatial coordinates to feature representations. Specifically, a neural field \(f_{\theta}: \mathbb{R}^d \rightarrow \mathbb{R}^c\) can map pixel coordinates \(x\) to RGB values, thereby representing images. These fields are typically parameterized by neural networks and optimized to approximate a target signal \(f_\theta\) within a reconstruction task.</p>

<p>While this approach results in continuous representations, it also presents a significant drawback. For multiple signals, the weights \(\theta_f\) must be optimized separately for each signal \(f\) This leads to a lack of shared structure across different signals and necessitates training separate models for each individual signal.</p>
<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        

<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/2024-06-15-equivariant-neural-fields/nf-480.webp 480w,/assets/img/2024-06-15-equivariant-neural-fields/nf-800.webp 800w,/assets/img/2024-06-15-equivariant-neural-fields/nf-1400.webp 1400w," sizes="95vw" type="image/webp"></source>
    
    <img src="/assets/img/2024-06-15-equivariant-neural-fields/nf.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

    </div>
</div>
<div class="caption">
    Neural Fields. when applied to images, a neural field $f_\theta$ maps coordinates $x \in \mathbb{R}^2$ to pixel values $I(x) \in \mathbb{R}^3$.
</div>

<p>Conditional Neural Fields (CNFs) extend this concept of neural fields by introducing a conditioning variable \(z_f\) that modulates the neural field for a specific signal \(f\). This enhancement allows CNFs to effectively represent an entire dataset of signals \(f \in \mathcal{D}\) using a single, shared set of weights \(\theta\) along with a set of unique conditioning variables \(z_f\). Since these representations are signal-specific, they latents can be used as a representation in downstream tasks. This approach has been successful in various tasks, including classification <d-cite key="dupont2022data"></d-cite>, segmentation <d-cite key="zhang20233dshape2vecset"></d-cite>, and even solving partial differential equations<d-cite key="yin2022continuous"></d-cite> <d-cite key="knigge2024pde"></d-cite>.</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        

<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/2024-06-15-equivariant-neural-fields/cnf-480.webp 480w,/assets/img/2024-06-15-equivariant-neural-fields/cnf-800.webp 800w,/assets/img/2024-06-15-equivariant-neural-fields/cnf-1400.webp 1400w," sizes="95vw" type="image/webp"></source>
    
    <img src="/assets/img/2024-06-15-equivariant-neural-fields/cnf.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

    </div>
</div>
<div class="caption">
    Conditional Neural Fields. Conditional neural fields extend neural fields by introducing a conditioning variable $z$ that modulates the shared base field $f_\theta$.
</div>

<p>However, conventional CNFs often lack geometric interpretability, they are able to capture textures and appearances which is shown by their performance in reconstruction. However, they do struggle to encode explicit geometric information necessary for tasks requiring spatial reasoning. Think for example of simple geometric transformations like rotations or translations, which are not inherently captured by CNFs; it is unclear how these transformations would manifest in the latent space.</p>

<h3 id="introducing-equivariant-neural-fields">Introducing Equivariant Neural Fields</h3>

<p>Equivariant Neural Fields (ENFs) address this limitation by grounding neural field representations in geometry. ENFs use latent point clouds as conditioning variables, where each point is a tuple consisting of a pose and a context vector. This grounding ensures that transformations in the field correspond to transformations in the latent space, a property known as equivariance.</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        

<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/2024-06-15-equivariant-neural-fields/ENF_latents-480.webp 480w,/assets/img/2024-06-15-equivariant-neural-fields/ENF_latents-800.webp 800w,/assets/img/2024-06-15-equivariant-neural-fields/ENF_latents-1400.webp 1400w," sizes="95vw" type="image/webp"></source>
    
    <img src="/assets/img/2024-06-15-equivariant-neural-fields/ENF_latents.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

    </div>
</div>
<div class="caption">
    Equivariant Neural Fields parameterize the conditioning variable $z$ as an attributed point-cloud of poses $p_i$ and corresponding context vectors $\mathbf{c}_i$: $z = \{ (p_i, \mathbf{c}_i \}_{i=0}^N$, explicitly grounding the latent space in geometry. 
</div>

<h3 id="key-properties-of-enfs">Key Properties of ENFs</h3>

<ul>
  <li>
<strong>Equivariance</strong>: If the field transforms, the latent representation transforms accordingly. This property ensures that the latent space preserves geometric patterns, enabling better geometric reasoning.</li>
  <li>
<strong>Weight Sharing</strong>: ENFs utilize shared weights over similar local patterns, leading to more efficient learning.</li>
  <li>
<strong>Localized Representations</strong>: The latent point sets in ENFs enable localized cross-attention mechanisms, enhancing interpretability and allowing unique field editing capabilities.</li>
</ul>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        

<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/2024-06-15-equivariant-neural-fields/enf-properties-480.webp 480w,/assets/img/2024-06-15-equivariant-neural-fields/enf-properties-800.webp 800w,/assets/img/2024-06-15-equivariant-neural-fields/enf-properties-1400.webp 1400w," sizes="95vw" type="image/webp"></source>
    
    <img src="/assets/img/2024-06-15-equivariant-neural-fields/enf-properties.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

    </div>
</div>
<div class="caption">
    Illustration of key properties of Equivariant Neural Fields. ENFs exhibit equivariance by weight-sharing over local patterns through a latent set of poses and context vectors. This enables localized representations and geometric reasoning in the latent space.
</div>

<h3 id="use-of-neural-fields-in-downstream-tasks">Use of Neural Fields in downstream tasks</h3>
<p>As brief interjection, we provide some background on how NeFs are used in downstream tasks. As (a subset of) model NeF parameters are optimized reconstruct specific samples, these parameters may be used as a representation of their corresponding signals. These representations serve as input to downstream models for tasks such as classification, segmentation or even solving partial differential equations.</p>
<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        

<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/2024-06-15-equivariant-neural-fields/downstream-example-480.webp 480w,/assets/img/2024-06-15-equivariant-neural-fields/downstream-example-800.webp 800w,/assets/img/2024-06-15-equivariant-neural-fields/downstream-example-1400.webp 1400w," sizes="95vw" type="image/webp"></source>
    
    <img src="/assets/img/2024-06-15-equivariant-neural-fields/downstream-example.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

    </div>
</div>
<div class="caption">
    Using NeFs in downstream tasks. For "conventional" NeFs, the weights $\theta_j$ are used as input to a downstream model that can operate on the computational graph of the neural field. For CNFs, the latent vectors $z_j$ are used as representation instead, allowing the use of simple MLPs.
    In ENFs instead the latent point sets $z_j$ are used as input to the downstream model, allowing for preservation of geometric information in the downstream task through the use of equivariant graph models.
</div>

<h2 id="methodology">Methodology</h2>
<p>We now delve into the technical details of ENF, focusing on the key components that enable the model to ground continuous representations in geometry.</p>

<h3 id="requirements-for-equivariant-neural-fields">Requirements for Equivariant Neural Fields</h3>
<p>The equivariance or steerability property of ENFs can be formally defined as:</p>

\[\forall g \in G : f_{\theta}(g^{-1}x, z) = f_{\theta}(x, gz).\]

<p>This property ensures that if the field as a whole transforms, the latent representation will transform in a consistent manner. This is crucial for maintaining geometric coherence in the latent space.
In order reason about the application of a group action on $z$, the authors equip the latent space with a group action by defining $z$ as a set of tuples \((p_i, \mathbf{c}_i)\), where $G$ acts on $z$ by transforming poses \(p_i: gz = \{(gp_i, \mathbf{c}_i)\}_{i=1}^N\).</p>

<p>For a neural field to satisfy the steerability property, the authors show it must be bi-invariant with respect to both coordinates and latents. 
This means that the field $ f_{\theta} $ must remain unchanged under group transformations applied to both the input coordinates and the latent point cloud, i.e.:</p>

\[\forall g \in G: f_\theta(gx, gz) = f_\theta(x, z).\]

<p>This observation is leveraged to define the architecture of ENFs, ensuring that the model is equivariant by design.</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        

<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/2024-06-15-equivariant-neural-fields/enf-comm-diag-480.webp 480w,/assets/img/2024-06-15-equivariant-neural-fields/enf-comm-diag-800.webp 800w,/assets/img/2024-06-15-equivariant-neural-fields/enf-comm-diag-1400.webp 1400w," sizes="95vw" type="image/webp"></source>
    
    <img src="/assets/img/2024-06-15-equivariant-neural-fields/enf-comm-diag.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

    </div>
</div>
<div class="caption">
    Commutative diagram illustrating the steerability of ENFs. 
</div>

<h3 id="equivariance-through-bi-invariant-cross-attention">Equivariance through Bi-invariant Cross-Attention</h3>
<p>ENFs utilize a bi-invariant cross-attention mechanism to parametrize the neural fields in order to achieve the aforementioned steerability property.
The cross-attention operation is defined as:
$ f_{\theta}(x, z) = \sum_{i=1}^{N} \text{att}(x, z) v(a(x, p_i), c_i) $
where $ a(x, p_i) $ is an invariant pair-wise attribute that captures the geometric relationship between the coordinate $ x $ and the latent pose $ p_i $, 
ensuring that the cross-attention operation respects the aforementioned bi-invariance condition.</p>

<p>Note that the choice of bi-invariant is related to the choice of group \(G\) and the specific application domain. For example,
in natural images \(G\) may be the group of 2D Euclidean transformations, while in 3D shape representations \(G\) may be the group of 3D rigid transformations,
leading to different choices of bi-invariant \(a(x, p_i)\). For a better understanding of bi-invariant properties we refer to <d-cite key="bekkers2023fast"></d-cite> which shows optimal invariant attributes in terms of expressivity for different groups.</p>

<h3 id="enforcing-locality-in-equivariant-neural-fields">Enforcing Locality in Equivariant Neural Fields</h3>
<p>To enforce locality, ENFs incorporate a Gaussian window into the attention mechanism. 
This ensures that each coordinate receives attention primarily from nearby latents, akin to the localized kernels in convolutional networks. 
This locality improves the interpretability of the latent representations, as specific features can be related to specific latent points $(p_i, \mathbf{c}_i)$.
Moreover, locality also improves parameter-efficiency by allowing for weight sharing over similar patterns.</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        

<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/2024-06-15-equivariant-neural-fields/enf-summ-480.webp 480w,/assets/img/2024-06-15-equivariant-neural-fields/enf-summ-800.webp 800w,/assets/img/2024-06-15-equivariant-neural-fields/enf-summ-1400.webp 1400w," sizes="95vw" type="image/webp"></source>
    
    <img src="/assets/img/2024-06-15-equivariant-neural-fields/enf-summ.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

    </div>
</div>
<div class="caption">
    Fitting different signals with ENFs. A field $f_j$ denoting a specific signal is represented by a set of localized latent points $z_j=\{ (p_i, \mathbf{c}_i)\}_{i=1}^N$. In the case of images (left), the latent points are distributed over the image plane. In the case of shapes (right), the latent points are distributed over 3D space.
</div>

<h2 id="experimental-validation">Experimental Validation</h2>
<p>The authors validate the properties of ENFs through various experiments on image and shape datasets, providing 
metrics for reconstruction and downstream classification. Moreover, authors play around with the ENFs latent space
to demonstrate the benefits of having a geometrically grounded latent space. A
separate study by Knigge et al. demonstrates the use of ENFs in modelling spatiotemporal dynamics.</p>

<h3 id="image-and-shape-reconstruction-and-classification">Image and Shape Reconstruction and Classification</h3>
<p>ENFs were evaluated on several image datasets, including CIFAR-10, CelebA, and STL-10. 
The results show that ENFs achieve higher peak signal-to-noise ratio (PSNR) in image reconstruction tasks compared to CNFs. 
This improvement is attributed to the geometric grounding and weight-sharing properties of ENFs.</p>

<table>
  <thead>
    <tr>
      <th><strong>Model</strong></th>
      <th><strong>Symmetry</strong></th>
      <th><strong>Cifar10</strong></th>
      <th><strong>CelebA</strong></th>
      <th><strong>STL-10</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Functa       <d-cite key="dupont2022data"></d-cite>
</td>
      <td>x</td>
      <td>31.9</td>
      <td>28.0</td>
      <td>20.7</td>
    </tr>
    <tr>
      <td><strong>ENF - abs pos</strong></td>
      <td>x</td>
      <td>31.5</td>
      <td>16.8</td>
      <td>22.8</td>
    </tr>
    <tr>
      <td><strong>ENF - rel pos</strong></td>
      <td>$\mathbb{R}^2$</td>
      <td><strong>34.8</strong></td>
      <td><strong>34.6</strong></td>
      <td><strong>26.8</strong></td>
    </tr>
    <tr>
      <td><strong>ENF - abs rel pos</strong></td>
      <td>SE(2)</td>
      <td>32.8</td>
      <td>32.4</td>
      <td>23.9</td>
    </tr>
    <tr>
      <td><strong>ENF - ponita</strong></td>
      <td>$\rm SE(2)$</td>
      <td>33.9</td>
      <td>32.9</td>
      <td>25.4</td>
    </tr>
  </tbody>
</table>

<div class="caption">
    Reconstruction accuracy for ENFs compared to CNFs on CIFAR-10, CelebA and STL10 for different choices of bi-invariant $a$.
</div>

<p>For classification, the authors used the latent point sets extracted from the trained ENF models. 
The classification accuracy on CIFAR-10 shows a significant improvement over conventional CNFs, 
highlighting the superior representation capabilities of ENFs.</p>

<table>
  <thead>
    <tr>
      <th><strong>Model</strong></th>
      <th><strong>Symmetry</strong></th>
      <th><strong>Cifar10</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Functa <d-cite key="dupont2022data"></d-cite>
</td>
      <td>x</td>
      <td>68.3</td>
    </tr>
    <tr>
      <td><strong>ENF - abs pos</strong></td>
      <td>x</td>
      <td>68.7</td>
    </tr>
    <tr>
      <td><strong>ENF - rel pos</strong></td>
      <td>$\mathbb{R}^2$</td>
      <td><strong>82.1</strong></td>
    </tr>
    <tr>
      <td><strong>ENF - abs rel pos</strong></td>
      <td>SE(2)</td>
      <td>70.9</td>
    </tr>
    <tr>
      <td><strong>ENF - ponita</strong></td>
      <td>SE(2)</td>
      <td>81.5</td>
    </tr>
  </tbody>
</table>

<div class="caption">
    Classification accuracy for ENFs compared to CNFs on CIFAR-10 for different choices of bi-invariant $a$.
</div>

<p>The authors also tested ENFs on shape datasets using Signed Distance Functions (SDFs). 
The results indicate that ENFs can effectively represent geometric shapes with high fidelity, 
further validating the geometric interpretability of the latent representations.</p>

<table>
  <thead>
    <tr>
      <th><strong>Model</strong></th>
      <th><strong>Reconstruction IoU (voxel)</strong></th>
      <th><strong>Reconstruction IoU (SDF)</strong></th>
      <th><strong>Classification</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Functa <d-cite key="dupont2022data"></d-cite>
</td>
      <td>99.44</td>
      <td>-</td>
      <td>93.6</td>
    </tr>
    <tr>
      <td><strong>ENF</strong></td>
      <td>-</td>
      <td>55</td>
      <td>89</td>
    </tr>
  </tbody>
</table>

<div class="caption">
    Shape reconstruction and classification metrics for ENFs compared to CNFs on ShapeNet.
</div>

<h3 id="latent-space-editing">Latent Space Editing</h3>
<p>The authors demonstrate the benefits of the geometrically grounded latent space in ENFs by performing latent space editing.</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        

<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/2024-06-15-equivariant-neural-fields/enf-carduck-480.webp 480w,/assets/img/2024-06-15-equivariant-neural-fields/enf-carduck-800.webp 800w,/assets/img/2024-06-15-equivariant-neural-fields/enf-carduck-1400.webp 1400w," sizes="95vw" type="image/webp"></source>
    
    <img src="/assets/img/2024-06-15-equivariant-neural-fields/enf-carduck.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

    </div>
</div>
<div class="caption">
    Latent space editing with ENFs. By construction, ENF representations can be stitched together to create new fields. Here, the authors demonstrate the ability to create a "car-duck" by combining the latent representations of reconstructions of a car and a duck.
</div>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        

<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/2024-06-15-equivariant-neural-fields/interpolation-480.webp 480w,/assets/img/2024-06-15-equivariant-neural-fields/interpolation-800.webp 800w,/assets/img/2024-06-15-equivariant-neural-fields/interpolation-1400.webp 1400w," sizes="95vw" type="image/webp"></source>
    
    <img src="/assets/img/2024-06-15-equivariant-neural-fields/interpolation.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

    </div>
</div>
<div class="caption">
    Localized latent space interpolation. The authors demonstrate the ability to interpolate between two neural fields by interpolating between their latent point sets. This allows for localized editing of the fields.
</div>

<h3 id="spatiotemporal-dynamics-modelling">Spatiotemporal Dynamics Modelling</h3>

<p>Another usecase for ENFs is highlighted in the paper “Space-Time Continuous PDE Forecasting using Equivariant Neural Fields” <d-cite key="knigge2024pde"></d-cite>.
Authors use the ENF as a continuous state representation for solving partial differential equations; learning to forecast dynamics by modelling them with a Neural ODE as a
flow in the latent space of the ENF. Since PDEs are often defined over continuous domains in terms of local differential operators, ENFs are well-suited to model these dynamics, as
they provide localized continuous representations.
This approach allows for symmetry-preserving continuous forecasting of spatiotemporal dynamics,
showing promising results on a variety of PDEs defined over different geometries. An initial state \(\nu_0:\mathcal{X}\rightarrow \mathbb{R}\) representing the current state of the PDE
is fit with a corresponding latent \(z_0\), which is unrolled in latent space with an equivariant graph-based neural ODE \(F_\psi\).</p>
<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        

<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/2024-06-15-equivariant-neural-fields/fig-enf-pde-480.webp 480w,/assets/img/2024-06-15-equivariant-neural-fields/fig-enf-pde-800.webp 800w,/assets/img/2024-06-15-equivariant-neural-fields/fig-enf-pde-1400.webp 1400w," sizes="95vw" type="image/webp"></source>
    
    <img src="/assets/img/2024-06-15-equivariant-neural-fields/fig-enf-pde.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

    </div>
</div>
<div class="caption">
    In Equivariant Neural Fields $f_\theta$, a field $\nu_t$ is represented by a set of latents 
$z^\nu_t = \{(p_{i}^\nu,\mathbf{c}_{i}^\nu)\}_{i=1}^N$ consisting of a pose $p_{i}$ and context vector $\mathbf{c}_{i}$. 
Using meta-learning, the initial latent $z^\nu_0$ is fit in only 3 SGD steps, after which an equivariant neural ODE $F_\psi$ models the solution as a latent flow.
</div>
<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        

<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/2024-06-15-equivariant-neural-fields/shallow-water-480.webp 480w,/assets/img/2024-06-15-equivariant-neural-fields/shallow-water-800.webp 800w,/assets/img/2024-06-15-equivariant-neural-fields/shallow-water-1400.webp 1400w," sizes="95vw" type="image/webp"></source>
    
    <img src="/assets/img/2024-06-15-equivariant-neural-fields/shallow-water.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

    </div>
</div>
<div class="caption">
Due to its continuous nature, the ENF forecasting model is able to natively handle zero-shot super-resolution, as demonstrated on the shallow water equations. 
Top: low resolution test sample at train resolution. Middle: high resolution test sample at test resolution. Bottom: ENF forecast at test resolution. 
</div>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        

<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/2024-06-15-equivariant-neural-fields/internally-heated-convection-480.webp 480w,/assets/img/2024-06-15-equivariant-neural-fields/internally-heated-convection-800.webp 800w,/assets/img/2024-06-15-equivariant-neural-fields/internally-heated-convection-1400.webp 1400w," sizes="95vw" type="image/webp"></source>
    
    <img src="/assets/img/2024-06-15-equivariant-neural-fields/internally-heated-convection.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

    </div>
</div>
<div class="caption">
Because of its geometric grounding, the model is able to handle complicated geometries, as demonstrated on internally heated convection equations in the ball.
</div>

<iframe src="/assets/plotly/2024-06-15-equivariant-neural-fields/navier-stokes.html" frameborder="0" scrolling="no" height="500px" width="100%" style="border: 1px dashed grey;"></iframe>
<div class="caption">
    The authors demonstrate the use of ENFs in modelling spatiotemporal dynamics by solving the Navier-Stokes 
equations over a 2D domain with periodic boundary conditions. The ENF respects the corresponding translational symmetries. Left: ground truth dynamics. Middle: ENF forecast. Right: Absolute forecast error. A test-sample is visualized, i.e. the model is unrolled from the initial state $\nu_0$. During training the model is supervised for 10 timesteps.
</div>

<h2 id="conclusion">Conclusion</h2>

<p>Equivariant Neural Fields leverage geometric grounding and equivariance properties to provide continuous signal representations preserving geometric information.
This approach opens up new possibilities for tasks that require geometric reasoning and localized representations, such as image and shape analysis, and shows promising results in 
forecasting spatiotemporal dynamics.</p>

<p>This blog post has explored the foundational concepts and the significant advancements brought forward by Equivariant Neural Fields. By grounding neural fields in geometry and incorporating equivariance properties, ENFs pave the way for more robust and interpretable continuous signal representations. As research in this area progresses, we can expect further innovations that leverage the geometric and localized nature of these fields, unlocking new potentials across diverse applications.</p>

      </d-article>

      <d-appendix>
        <d-footnote-list></d-footnote-list>
        <d-citation-list></d-citation-list>
      </d-appendix>

      <d-bibliography src="/assets/bibliography/2024-06-15-equivariant-neural-fields.bib"></d-bibliography>

      
      
    </div>

    <!-- Footer -->
    
  <footer class="sticky-bottom mt-5" role="contentinfo">
    <div class="container">
      © Copyright 2024
      
      
      . 
      
      
    </div>
  </footer>


    <!-- Bootsrap & MDB scripts -->
<script src="/assets/js/bootstrap.bundle.min.js"></script>
<!-- <script src="/assets/js/mdb.min.js"></script> -->
<script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    


    
  <!-- Scrolling Progress Bar -->
  <script type="text/javascript">
    /*
     * This JavaScript code has been adapted from the article
     * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar,
     * published on the website https://css-tricks.com on the 7th of May, 2014.
     * Couple of changes were made to the original code to make it compatible
     * with the `al-foio` theme.
     */
    const progressBar = $('#progress');
    /*
     * We set up the bar after all elements are done loading.
     * In some cases, if the images in the page are larger than the intended
     * size they'll have on the page, they'll be resized via CSS to accomodate
     * the desired size. This mistake, however, breaks the computations as the
     * scroll size is computed as soon as the elements finish loading.
     * To account for this, a minimal delay was introduced before computing the
     * values.
     */
    window.onload = function () {
      setTimeout(progressBarSetup, 50);
    };
    /*
     * We set up the bar according to the browser.
     * If the browser supports the progress element we use that.
     * Otherwise, we resize the bar thru CSS styling
     */
    function progressBarSetup() {
      if ('max' in document.createElement('progress')) {
        initializeProgressElement();
        $(document).on('scroll', function () {
          progressBar.attr({ value: getCurrentScrollPosition() });
        });
        $(window).on('resize', initializeProgressElement);
      } else {
        resizeProgressBar();
        $(document).on('scroll', resizeProgressBar);
        $(window).on('resize', resizeProgressBar);
      }
    }
    /*
     * The vertical scroll position is the same as the number of pixels that
     * are hidden from view above the scrollable area. Thus, a value > 0 is
     * how much the user has scrolled from the top
     */
    function getCurrentScrollPosition() {
      return $(window).scrollTop();
    }

    function initializeProgressElement() {
      let navbarHeight = $('#navbar').outerHeight(true);
      $('body').css({ 'padding-top': navbarHeight });
      $('progress-container').css({ 'padding-top': navbarHeight });
      progressBar.css({ top: navbarHeight });
      progressBar.attr({
        max: getDistanceToScroll(),
        value: getCurrentScrollPosition(),
      });
    }
    /*
     * The offset between the html document height and the browser viewport
     * height will be greater than zero if vertical scroll is possible.
     * This is the distance the user can scroll
     */
    function getDistanceToScroll() {
      return $(document).height() - $(window).height();
    }

    function resizeProgressBar() {
      progressBar.css({ width: getWidthPercentage() + '%' });
    }
    // The scroll ratio equals the percentage to resize the bar
    function getWidthPercentage() {
      return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
    }
  </script>


  
</body>
</html>
