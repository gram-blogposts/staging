<!DOCTYPE html>
<html>
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <!-- Metadata, OpenGraph and Schema.org -->




<!-- Standard metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<title>
  
  
    
      Applications of TopoX to Topological Deep Learning |  
    
  
</title>
<meta name="author" content=" ">
<meta name="description" content="Studying the properties of message passing accross TNNs using the TopoX Suite">

  <meta name="keywords" content="geometry, machine-learning, generative-models, deep-learning, representation-learning">










<!-- Bootstrap & MDB -->
<link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

<!-- Bootstrap Table -->


<!-- Fonts & Icons -->
<link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5">
<link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap">

<!-- Code Syntax Highlighting -->
<link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light">



<!-- Styles -->

<!-- pseudocode -->



  <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">

<link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e">
<link rel="canonical" href="http://localhost:4000/blog/2024/smpn/">

<!-- Dark Mode -->
<script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script>

  <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark">
  <script>
    initTheme();
  </script>


<!-- GeoJSON support via Leaflet -->


<!-- diff2html -->






    
      <!-- Medium Zoom JS -->
      <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script>
      <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script>
    
    <!-- jQuery -->
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    
  
    <!-- MathJax -->
    <script type="text/javascript">
      window.MathJax = {
        tex: {
          tags: 'ams',
        },
      };
    </script>
    <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js"></script>
    <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  


    <!-- Distill js -->
    <script src="/assets/js/distillpub/template.v2.js"></script>
    <script src="/assets/js/distillpub/transforms.v2.js"></script>
    <script src="/assets/js/distillpub/overrides.js"></script>
    
  </head>

  <body>
<d-front-matter>
    <script async type="text/json">
      {
            "title": "Applications of TopoX to Topological Deep Learning",
            "description": "Studying the properties of message passing accross TNNs using the TopoX Suite",
            "published": "June 30, 2024",
            "authors": [
              
              {
                "author": "Anonymous",
                "authorURL": "",
                "affiliations": [
                  {
                    "name": "",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script>
  </d-front-matter>

  
    <!-- Header -->
    <header>
  <!-- Nav Bar -->
  <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation">
    <div class="container">
      
        <a class="navbar-brand title font-weight-lighter" href="/">
          
            
            
            
          
        </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>

      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          

          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">about
              
            </a>
          </li>

          <!-- Other pages -->
          
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
              
                <li class="nav-item ">
                  
                  <a class="nav-link" href="/instructions/">instructions
                    
                  </a>
                </li>
              
            
          
            
              
                <li class="nav-item ">
                  
                  <a class="nav-link" href="/reviews/">reviews
                    
                  </a>
                </li>
              
            
          
          
            <!-- Toogle theme mode -->
            <li class="toggle-container">
              <button id="light-toggle" title="Change theme">
                <i class="ti ti-sun-moon" id="light-toggle-system"></i>
                <i class="ti ti-moon-filled" id="light-toggle-dark"></i>
                <i class="ti ti-sun-filled" id="light-toggle-light"></i>
              </button>
            </li>
          
        </ul>
      </div>
    </div>
  </nav>
  
    <!-- Scrolling Progress Bar -->
    <progress id="progress" value="0">
      <div class="progress-container">
        <span class="progress-bar"></span>
      </div>
    </progress>
  
</header>


    <!-- Content -->
    <div class="post distill">
      <d-title>
        <h1>Applications of TopoX to Topological Deep Learning</h1>
        <p>Studying the properties of message passing accross TNNs using the TopoX Suite</p>
      </d-title>
      
        <d-byline></d-byline>
      

      <d-article>
        
          <d-contents>
            <nav class="l-text figcaption">
              <h3>Contents</h3>
              
                <div>
                  <a href="#introduction">Introduction</a>
                </div>
                
              
                <div>
                  <a href="#message-passing-in-gnns">Message Passing in GNNs</a>
                </div>
                
              
                <div>
                  <a href="#equivariance-and-invariance">Equivariance and Invariance</a>
                </div>
                
              
                <div>
                  <a href="#higher-order-networks-and-why-topology-is-useful">Higher-order networks and why topology is useful</a>
                </div>
                
              
                <div>
                  <a href="#"></a>
                </div>
                
                  <ul>
                    
                      <li>
                        <a href="#higher-order-neighbourhoods">Higher-order neighbourhoods</a>
                      </li>
                    
                  </ul>
                
              
                <div>
                  <a href="#lifting-techniques">Lifting techniques</a>
                </div>
                
              
                <div>
                  <a href="#"></a>
                </div>
                
                  <ul>
                    
                      <li>
                        <a href="#vietoris-rips-complex">Vietoris-Rips Complex</a>
                      </li>
                    
                      <li>
                        <a href="#alpha-complex">Alpha Complex</a>
                      </li>
                    
                  </ul>
                
              
                <div>
                  <a href="#do-invariances-hold">Do invariances hold ?</a>
                </div>
                
              
                <div>
                  <a href="#"></a>
                </div>
                
                  <ul>
                    
                      <li>
                        <a href="#in-simplices-too">In simplices too ?</a>
                      </li>
                    
                  </ul>
                
              
                <div>
                  <a href="#the-new-standard-topox">The new standard: TopoX</a>
                </div>
                
              
                <div>
                  <a href="#"></a>
                </div>
                
                  <ul>
                    
                      <li>
                        <a href="#building-structure">Building structure</a>
                      </li>
                    
                      <li>
                        <a href="#mini-batching-detour">Mini-batching detour</a>
                      </li>
                    
                      <li>
                        <a href="#piecing-it-all-together">Piecing it all together</a>
                      </li>
                    
                  </ul>
                
              
                <div>
                  <a href="#experiments">Experiments</a>
                </div>
                
              
                <div>
                  <a href="#conclusions">Conclusions</a>
                </div>
                
              
            </nav>
          </d-contents>
        
        <h1 id="introduction">Introduction</h1>

<p>Representation learning using Graph Neural Networks (GNNs) is rapidly growing approach to complex tasks in chemistry <d-cite key="ballester2024attending,bekkers2023fast,eijkelboom2023n,battiloro2024n"></d-cite>. Particularly, in a subset of these tasks a crucial aspect is maintaining equivariance to different transformations such as <em>translation</em>, <em>rotation</em> and <em>reflection</em>. Learning representations such that <strong>equivariance</strong> or <strong>invariance</strong> can be applied has proved very helpful <d-cite key="bekkers2023fast,eijkelboom2023n"></d-cite>. Additionally, incorporating higher-order relations in GNNs such that they encode more complex topological spaces is a recent effort to increase the expressivity of GNNs <d-cite key="hajij2022topological,eijkelboom2023n,giusti2024topological"></d-cite>.</p>

<p>The aim of this blogpost is to draw attention to Topological Deep Learning (TDL) by using the suite of Python packages TopoX <d-cite key="hajij2024topox"></d-cite> to replicate the work of <d-cite key="eijkelboom2023n"></d-cite> and show how much simpler development is in this framework. Additionally, we experiment with a different topological spaces with more geometric information and compare the results with the original work.</p>

<!--
 We will introduce the concepts needed to address **equivariance** and **invariance** as well as definitions of what exactly constitute this *higher-order* structures. Then, we will introduce TopoX and the benefits of development in this framework, show some examples and present the results. Our results show that development in this platform is beneficial for the investigator conducting research as well as the scientific community. New architectures and experiments developed using TopoX allow a standardaized way to share this among people interested in TDL.
 -->
<hr>

<h1 id="message-passing-in-gnns">Message passing in GNNs</h1>
<p>Let \(G = (V,E)\) be a graph consisting of nodes \(V\) and edges \(E\). Then let each node \(v_i \in V\) and edge \(e_{ij} \in E\) have an associated node feature \(\mathbf{f}_i \in \mathbb{R}^{c_n}\) and edge feature \(a_{ij} \in \mathbb{R}^{c_e}\), with dimensionality \(c_n, c_e \in \mathbb{N}_{&gt;0}\). Then, we define a <em>message passing layer</em> as:</p>

\[\begin{equation}\label{compute_message}
\mathbf{m}_{i j}=\phi_m\left(\mathbf{h}_i^l, \mathbf{h}_j^l, \mathbf{a}_{i j}\right)
\end{equation}\]

<p>\(\begin{equation}\label{aggregate_messages}
    \mathbf{m}_i=\underset{j \in \mathcal{N}(i)}{\operatorname{Agg}} \mathbf{m}_{i j}
\end{equation}\)
\(\begin{equation}\label{update_hidden}
    \mathbf{h}_i^{l+1}=\phi_h\left(\mathbf{h}_i^l, \mathbf{m}_i\right)
\end{equation}\)</p>

<hr>

<h1 id="equivariance-and-invariance">Equivariance and Invariance</h1>

<p><strong>Invariance</strong> is when an object or set of objects remain the same after a transformation. In contrast, <strong>equivariance</strong> is a symmetry with respect to a function and a transformation. At first glance this definitions might be hard to picture, however with some group theory they will become more clear.</p>

<p>Let \(G\) be a group and let \(X\), \(Y\) be sets on which \(G\) acts. A function \(f: X \rightarrow Y\) is called equivariant with respect to \(G\) if it commutes with the group action. Equation \ref{eq:equi} expresses this notion formally.</p>

\[\begin{equation}\label{eq:equi}
f(g \cdot x)=g \cdot f(x)
\end{equation}\]

<p>Conversly, Equation \ref{eq:inv} shows that <strong>invariance</strong> is when the application of the transformation \(g \in G\) does not affect the output of the map \(f\),</p>

\[\begin{equation}\label{eq:inv}
f(g \cdot x)=f(x) 
\end{equation}\]

<hr>

<h1 id="higher-order-networks-and-why-topology-is-useful">Higher-order networks and why topology is useful</h1>
<p>Regular graph relations fall short of modelling multi-interacions, as such we turn to higher order networks. An <em>abstract simplicial complex</em> (ASC) is the combinatorial expression of a non-empty set of simplices.</p>

<p>Concretly, let \(\mathcal{P}(S)\) be the powerset of \(S\) and another set \(\mathcal{K} \subset \mathcal{P}(S)\), then \(\mathcal{K}\) is an ASC if for every \(X \in \mathcal{K}\) and every non-empty \(Y \subseteq X\) it holds that \(Y \in \mathcal{K}\). Also, we define \(\mid\mathcal{K}\mid\) to be the highest cardinality of a simplex in an ASC minus 1. If the rank is \(r\) then it holds \(\forall X \in \mathcal{K}: r \geq \mid X \mid\).</p>

<!-- 
## Geometric realization

Although an ASC is a purely combinatorial object, it always entails a **geometric realization**. For the case of $$r=1$$ then it can be represented as a graph. A **simplicial complex** is the geometric realization of an ASC, constructed out of the underlying geometric of the points in $$ \mathcal{K}$$. As such, they can be constructed using the set of verticies $$ V $$ of a graph as disjoint points in space or even taking a graph $$ G = (V, E) $$ where $$ V $$ is the set of 0-cells and $$ E $$ is the set of 1-cells. Transforming a set of points to a simplicial complex is called **lifting**. 
 
As an example, we may consider the clique lifting procedure. A *clique* $$ C \subseteq V $$, such that $$ C $$ is complete. In other words, there is an edge between every pair of vertices. In this lifting procedure each clique will become an r-cell and have it's own set of neighbours. Note that the time complexity of this lift is $$ \mathcal{O}(3^{n/3}) $$
-->

<h2 id="higher-order-neighbourhoods">Higher-order neighbourhoods</h2>
<p>To define proximite relations such as graph adjacencies in \(r\)-simplex we establish some definitions. We will work with only two types of adjacencies as they have proven to be as expressive as using all of them. First, let \(\sigma\) and \(\tau\) be two simplices, we say that \(\sigma \text{ is on the bound of } \tau\) as \(\sigma \prec \tau\) and: 1) \(\sigma \subset \tau\), 2) \(\nexists \delta: \sigma  \subset \delta \subset \tau\)</p>

<p>Equation \ref{eq:bound_adj} referes to the relation between a \(r\)-simplex and the \((r-1)\)-simplex that compose it. Equation \ref{eq:bound_up} referes to the relationship between  \((r-1)\)-simplex and other \((r-1)\)-simplex that are a part of a higher \(r\)-simplex. They are also refered to as <strong>cofaces</strong> in the literature <d-cite key="hajij2022topological"></d-cite>.</p>

\[\begin{equation}\label{eq:bound_adj}
\mathcal{B}(\sigma) = \{\tau \mid \tau \prec \sigma\}
\end{equation}\]

\[\begin{equation}\label{eq:bound_up}
\mathcal{N}_{\uparrow}(\sigma) = \{\tau \mid \exists \delta, \tau \prec \delta \land \sigma \prec \delta\}
\end{equation}\]

<hr>
<h1 id="lifting-techniques">Lifting techniques</h1>
<p>How a higher-order representation of points in the space or a particular graph is to be constructed  depends on the properties that want to be attained and, as always, how efficient is to compute. Letâ€™s go over some alternatives.</p>

<h2 id="vietoris-ripps-complex">Vietoris-Ripps Complex</h2>
<p>The Vietoris-Ripps complex is a common way to form a topological space. The time complexity for generating of the procedure depends on the maximum dimension of the simplices in the complex \(r\) and number of points \(n\)  given by \(\mathcal{O}(n^{r+1})\). If the points are embedded in Euclidean space then it is an approximation of a larger and richer complex called the <em>Cech Complex</em>.</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        

<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/2024-06-30-smpn/rips-lift-480.webp 480w,/assets/img/2024-06-30-smpn/rips-lift-800.webp 800w,/assets/img/2024-06-30-smpn/rips-lift-1400.webp 1400w," sizes="95vw" type="image/webp"></source>
    
    <img src="/assets/img/2024-06-30-smpn/rips-lift.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

    </div>
</div>

<h2 id="alpha-complex">Alpha Complex</h2>
<p>The alpha complex is a fundamental data structure from computational geometry given by a subset \(\sigma = \{x_{i0},...,x_{ik} \}\subset S\) belongs to \(\operatorname{Alpha}(S,r)\) if there exists a point \(y \in \mathbb{R}^m\) that is equidistant from every member of \(\sigma\), so that</p>

<p>\(\begin{align*}
    \rho := || y- x_{i0}||=...=||y-x_{ik}|| \leq r
\end{align*}\)
and thus \(||y-x|| \leq r\ \ \  \forall x \in S\). 
Formally, the alpha complex is defined as the collection:</p>

\[\begin{align*}
    \operatorname{Alpha}(S, r)=\left\{\sigma \subset S: \bigcap_{x \in \sigma} V_x(r) \neq \emptyset\right\}
\end{align*}\]

<p>A subset \(\sigma\) of size \(k+1\) is called a k-dimensional simplex of \(\operatorname{Alpha}(S,r)\).</p>

<hr>

<h1 id="do-invariances-hold-">Do invariances hold ?</h1>

<p>Equation \ref{eq:msg_eq} comes to replace \ref{compute_message} with our invariant function. Addtionally, to make the network equivariant we introduce feature vector  \(x\) which contains the positional coordinates in euclidean space. Equation \ref{eq:pos_update} refers to the update in the position embedding of the node. The proofs that with this condition equivariance holds can be found in <d-cite key="satorras2021n"></d-cite>.</p>

\[\begin{equation}\label{eq:msg_eq}
 \mathbf{m}_{i j}=\phi_m\left(\mathbf{h}_i^l, \mathbf{h}_j^l, \operatorname{lnv}\left(\mathbf{x}_i^l, \mathbf{x}_j^l\right), \mathbf{a}_{i j}\right)
 \end{equation}\]

\[\begin{equation}\label{eq:pos_update}
    \mathbf{x}_i^{l+1}=\mathbf{x}_i^l+C \sum_{j \neq i}\left(\mathbf{x}_i^l-\mathbf{x}_j^l\right) \phi_x\left(\mathbf{m}_{i j}\right)
\end{equation}\]

<h2 id="in-simplices-too-">In simplices too ?</h2>

<p>Using the previous definitions of neighbourhoods <d-cite key="eijkelboom2023n"></d-cite> defines a message for each neighbourhood as Equation \ref{eq:msg_boundary} and Equation \ref{eq:msg_ua} and replaces the hidden representation update to take these messages into account in Equation \ref{eq:update_sc}.</p>

\[\begin{equation}\label{eq:msg_boundary}
m_{\mathcal{B}}(\sigma) = \underset{\tau \in \mathcal{B}(\sigma)}{\operatorname{Agg}} (\phi_{\mathcal{B}}(h^l_{\sigma}, h^l_{\tau})
\end{equation}\]

\[\begin{equation}\label{eq:msg_ua}
m_{\mathcal{N}_{\uparrow}}(\sigma) = \underset{\tau \in \mathcal{N}_{\uparrow}(\sigma)}{\operatorname{Agg}} (\phi_{\mathcal{N}_{\uparrow}}(h^l_{\sigma}, h^l_{\tau}))
\end{equation}\]

\[\begin{equation}\label{eq:update_sc}
h_{\sigma}^{l+1} = \phi_{h} (h_{\sigma}^l, m_{\mathcal{B}}(\sigma), m_{\mathcal{N}_{\uparrow}}(\sigma))
\end{equation}\]

<p>Finally, they define a graph embedding as Equation \ref{eq:agg_simp} where the simplices \(\mathcal{K}\) of each dimension \(r\) will be aggregated and the final embedding of the complex will be the concatenation of the embedding of each dimension.</p>

\[\begin{equation}\label{eq:agg_simp}

h_{\mathcal{K}} = \bigoplus_{i=0}^{r} \underset{\sigma \in \mathcal{K}, |\sigma|=i+1}{\operatorname{Agg}} h_\sigma
\end{equation}\]

<hr>
<h1 id="the-new-standard-topox">The new standard: TopoX</h1>

<p>TopoX is a suite of Python packages that aim to provide a standard for developments in TDL. It encompases TopoModelX, TopoNetX, TopoEmbeddX and now TopoBenchmarX. Each of them having functionalities according to their name in the topological domain. Next, we ilustrate the development process and reproduction of <d-cite key="eijkelboom2023n"></d-cite> in the TopoX suite. Additionally, as a base project we use the <a href="https://github.com/pyt-team/challenge-icml-2024" rel="external nofollow noopener" target="_blank">ICML TDL Challenge 2024</a> for development, which structures all these packages together to be used in the development cycle. Additionally, we use the Pytorch Geometric QM9 dataset as it contains graph data.</p>

<h2 id="building-structure">Building structure</h2>

<p>The first thing we are concerned with is the <strong>lifting</strong> of our initial graph or set of points. To perform that task we will make use of GHUDI <d-cite key="gudhi:urm"></d-cite>, a Python library with many methods mainly used for Topological Data Analysis. Additionally, we add the option to fully connect all the \(0\)-simplex.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">rips_lift</span><span class="p">(</span><span class="n">graph</span><span class="p">:</span> <span class="n">torch_geometric</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Data</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">dis</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">fc_nodes</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SimplicialComplex</span><span class="p">:</span>
    <span class="n">x_0</span><span class="p">,</span> <span class="n">pos</span> <span class="o">=</span> <span class="n">graph</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">graph</span><span class="p">.</span><span class="n">pos</span>

    <span class="n">points</span> <span class="o">=</span> <span class="p">[</span><span class="n">pos</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">tolist</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">pos</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span>

    <span class="n">rips_complex</span> <span class="o">=</span> <span class="n">gudhi</span><span class="p">.</span><span class="nc">RipsComplex</span><span class="p">(</span><span class="n">points</span><span class="o">=</span><span class="n">points</span><span class="p">,</span> <span class="n">max_edge_length</span><span class="o">=</span><span class="n">dis</span><span class="p">)</span>
    <span class="n">simplex_tree</span><span class="p">:</span> <span class="n">SimplexTree</span>  <span class="o">=</span> <span class="n">rips_complex</span><span class="p">.</span><span class="nf">create_simplex_tree</span><span class="p">(</span><span class="n">max_dimension</span><span class="o">=</span><span class="n">dim</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">fc_nodes</span><span class="p">:</span>
        <span class="n">nodes</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">x_0</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span>
        <span class="k">for</span> <span class="n">edge</span> <span class="ow">in</span> <span class="nf">combinations</span><span class="p">(</span><span class="n">nodes</span><span class="p">,</span> <span class="mi">2</span><span class="p">):</span>
            <span class="n">simplex_tree</span><span class="p">.</span><span class="nf">insert</span><span class="p">(</span><span class="n">edge</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">SimplicialComplex</span><span class="p">.</span><span class="nf">from_gudhi</span><span class="p">(</span><span class="n">simplex_tree</span><span class="p">)</span></code></pre></figure>

<p>Now we will use the <code class="language-plaintext highlighter-rouge">Graph2SimplicialLifting</code> base class and override the lifting methods such that we transform an input <code class="language-plaintext highlighter-rouge">pytorch_geometric.data.Data</code>.</p>

<p>We override the init to include the <code class="language-plaintext highlighter-rouge">delta</code> parameter that defines the <em>range</em> of the Vietoris-Ripps lift.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">delta</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">delta</span> <span class="o">=</span> <span class="n">delta</span></code></pre></figure>

<p>Now, we override the main method called <code class="language-plaintext highlighter-rouge">lifted_topology</code>.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"> <span class="k">def</span> <span class="nf">lift_topology</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">torch_geometric</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Data</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
        <span class="n">simplicial_complex</span> <span class="o">=</span> <span class="nf">rips_lift</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">complex_dim</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">delta</span><span class="p">)</span>

        <span class="n">feature_dict</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">node</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">x</span><span class="p">):</span>
            <span class="n">feature_dict</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">node</span>

        <span class="n">simplicial_complex</span><span class="p">.</span><span class="nf">set_simplex_attributes</span><span class="p">(</span><span class="n">feature_dict</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">features</span><span class="sh">'</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">_get_lifted_topology</span><span class="p">(</span><span class="n">simplicial_complex</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span></code></pre></figure>

<p>Then, we move on to <code class="language-plaintext highlighter-rouge">_lifted_topology</code> where the object is built. The <code class="language-plaintext highlighter-rouge">get_complex_connectivity</code> is provided by the library and constructs the connectivity matrices.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python">    <span class="k">def</span> <span class="nf">_get_lifted_topology</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span> <span class="n">simplicial_complex</span><span class="p">:</span> <span class="n">SimplicialComplex</span><span class="p">,</span> <span class="n">graph</span><span class="p">:</span> <span class="n">nx</span><span class="p">.</span><span class="n">Graph</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
        <span class="n">lifted_topology</span> <span class="o">=</span> <span class="nf">get_complex_connectivity</span><span class="p">(</span>
            <span class="n">simplicial_complex</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">complex_dim</span><span class="p">,</span> <span class="n">signed</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">signed</span>
        <span class="p">)</span>

        <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">simplicial_complex</span><span class="p">.</span><span class="n">dim</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">lifted_topology</span><span class="p">[</span><span class="sa">f</span><span class="sh">'</span><span class="s">adjacency_</span><span class="si">{</span><span class="n">r</span><span class="si">}</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">lifted_topology</span><span class="p">[</span><span class="sa">f</span><span class="sh">'</span><span class="s">adjacency_</span><span class="si">{</span><span class="n">r</span><span class="si">}</span><span class="sh">'</span><span class="p">].</span><span class="nf">to_dense</span><span class="p">().</span><span class="nf">nonzero</span><span class="p">().</span><span class="nf">t</span><span class="p">().</span><span class="nf">contiguous</span><span class="p">()</span>
            <span class="n">lifted_topology</span><span class="p">[</span><span class="sa">f</span><span class="sh">'</span><span class="s">incidence_</span><span class="si">{</span><span class="n">r</span><span class="si">}</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">lifted_topology</span><span class="p">[</span><span class="sa">f</span><span class="sh">'</span><span class="s">incidence_</span><span class="si">{</span><span class="n">r</span><span class="si">}</span><span class="sh">'</span><span class="p">].</span><span class="nf">to_dense</span><span class="p">().</span><span class="nf">nonzero</span><span class="p">().</span><span class="nf">t</span><span class="p">().</span><span class="nf">contiguous</span><span class="p">()</span>


        <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">simplicial_complex</span><span class="p">.</span><span class="n">dim</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">lifted_topology</span><span class="p">[</span><span class="sa">f</span><span class="sh">'</span><span class="s">x_idx_</span><span class="si">{</span><span class="n">r</span><span class="si">}</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">simplicial_complex</span><span class="p">.</span><span class="nf">skeleton</span><span class="p">(</span><span class="n">r</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">int</span><span class="p">)</span>

        <span class="n">lifted_topology</span><span class="p">[</span><span class="sh">"</span><span class="s">x_0</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">(</span>
            <span class="nf">list</span><span class="p">(</span><span class="n">simplicial_complex</span><span class="p">.</span><span class="nf">get_simplex_attributes</span><span class="p">(</span><span class="sh">"</span><span class="s">features</span><span class="sh">"</span><span class="p">,</span> <span class="mi">0</span><span class="p">).</span><span class="nf">values</span><span class="p">())</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">lifted_topology</span></code></pre></figure>

<p>Now we have to do a quick detour to talk about <strong>mini-batching</strong></p>

<h2 id="mini-batching-detour">Mini-batching detour</h2>

<p>To be brief in PyG a dataset compromising graphs is concatenated into one big graph that is represented by a block-diagonal matrix. There is a detailed explanation <a href="https://pytorch-geometric.readthedocs.io/en/latest/advanced/batching.html" rel="external nofollow noopener" target="_blank">here</a>.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">class</span> <span class="nc">SimplexData</span><span class="p">(</span><span class="n">torch_geometric</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Data</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__inc__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">if</span> <span class="sh">'</span><span class="s">adjacency</span><span class="sh">'</span> <span class="ow">in</span> <span class="n">key</span><span class="p">:</span>
            <span class="n">rank</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">key</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">'</span><span class="s">_</span><span class="sh">'</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="nf">getattr</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="sa">f</span><span class="sh">'</span><span class="s">x_</span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="sh">'</span><span class="p">).</span><span class="nf">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)])</span>
            <span class="c1">#return torch.tensor([[getattr(self, f'x_{rank}').size(0)], [getattr(self, f'x_{rank}').size(0)]])
</span>        <span class="k">elif</span> <span class="sh">'</span><span class="s">incidence</span><span class="sh">'</span> <span class="ow">in</span> <span class="n">key</span><span class="p">:</span>
            <span class="n">rank</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">key</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">'</span><span class="s">_</span><span class="sh">'</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="nf">getattr</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="sa">f</span><span class="sh">'</span><span class="s">x_</span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="sh">'</span><span class="p">).</span><span class="nf">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)])</span>
            <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([[</span><span class="nf">getattr</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="sa">f</span><span class="sh">'</span><span class="s">x_</span><span class="si">{</span><span class="n">rank</span><span class="o">-</span><span class="mi">1</span><span class="si">}</span><span class="sh">'</span><span class="p">).</span><span class="nf">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)],</span> <span class="p">[</span><span class="nf">getattr</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="sa">f</span><span class="sh">'</span><span class="s">x_</span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="sh">'</span><span class="p">).</span><span class="nf">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)]])</span>
        <span class="k">elif</span> <span class="n">key</span> <span class="o">==</span> <span class="sh">'</span><span class="s">x_0</span><span class="sh">'</span> <span class="ow">or</span> <span class="n">key</span> <span class="o">==</span> <span class="sh">'</span><span class="s">x_idx_0</span><span class="sh">'</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="nf">getattr</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="sa">f</span><span class="sh">'</span><span class="s">x_0</span><span class="sh">'</span><span class="p">).</span><span class="nf">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)])</span>
        <span class="k">elif</span> <span class="n">key</span> <span class="o">==</span> <span class="sh">'</span><span class="s">x_1</span><span class="sh">'</span> <span class="ow">or</span> <span class="n">key</span> <span class="o">==</span> <span class="sh">'</span><span class="s">x_idx_1</span><span class="sh">'</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="nf">getattr</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="sa">f</span><span class="sh">'</span><span class="s">x_0</span><span class="sh">'</span><span class="p">).</span><span class="nf">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)])</span>
        <span class="k">elif</span> <span class="n">key</span> <span class="o">==</span> <span class="sh">'</span><span class="s">x_2</span><span class="sh">'</span> <span class="ow">or</span> <span class="n">key</span> <span class="o">==</span> <span class="sh">'</span><span class="s">x_idx_2</span><span class="sh">'</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="nf">getattr</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="sa">f</span><span class="sh">'</span><span class="s">x_0</span><span class="sh">'</span><span class="p">).</span><span class="nf">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)])</span>
        <span class="k">elif</span> <span class="sh">'</span><span class="s">index</span><span class="sh">'</span> <span class="ow">in</span> <span class="n">key</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">num_nodes</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="nf">super</span><span class="p">().</span><span class="nf">__inc__</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__cat_dim__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">if</span> <span class="sh">'</span><span class="s">adjacency</span><span class="sh">'</span> <span class="ow">in</span> <span class="n">key</span> <span class="ow">or</span> <span class="sh">'</span><span class="s">incidence</span><span class="sh">'</span> <span class="ow">in</span> <span class="n">key</span> <span class="ow">or</span> <span class="sh">'</span><span class="s">index</span><span class="sh">'</span> <span class="ow">in</span> <span class="n">key</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">0</span></code></pre></figure>

<h2 id="piecing-it-all-together">Piecing it all together</h2>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">class</span> <span class="nc">SimplicialVietorisRipsLifting</span><span class="p">(</span><span class="n">Graph2SimplicialLifting</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">delta</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">delta</span> <span class="o">=</span> <span class="n">delta</span>

    <span class="k">def</span> <span class="nf">lift_topology</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">torch_geometric</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Data</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
        <span class="n">simplicial_complex</span> <span class="o">=</span> <span class="nf">rips_lift</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">complex_dim</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">delta</span><span class="p">)</span>

        <span class="n">feature_dict</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">node</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">x</span><span class="p">):</span>
            <span class="n">feature_dict</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">node</span>

        <span class="n">simplicial_complex</span><span class="p">.</span><span class="nf">set_simplex_attributes</span><span class="p">(</span><span class="n">feature_dict</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">features</span><span class="sh">'</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">_get_lifted_topology</span><span class="p">(</span><span class="n">simplicial_complex</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_get_lifted_topology</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span> <span class="n">simplicial_complex</span><span class="p">:</span> <span class="n">SimplicialComplex</span><span class="p">,</span> <span class="n">graph</span><span class="p">:</span> <span class="n">nx</span><span class="p">.</span><span class="n">Graph</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
        <span class="n">lifted_topology</span> <span class="o">=</span> <span class="nf">get_complex_connectivity</span><span class="p">(</span>
            <span class="n">simplicial_complex</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">complex_dim</span><span class="p">,</span> <span class="n">signed</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">signed</span>
        <span class="p">)</span>

        <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">simplicial_complex</span><span class="p">.</span><span class="n">dim</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">lifted_topology</span><span class="p">[</span><span class="sa">f</span><span class="sh">'</span><span class="s">adjacency_</span><span class="si">{</span><span class="n">r</span><span class="si">}</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">lifted_topology</span><span class="p">[</span><span class="sa">f</span><span class="sh">'</span><span class="s">adjacency_</span><span class="si">{</span><span class="n">r</span><span class="si">}</span><span class="sh">'</span><span class="p">].</span><span class="nf">to_dense</span><span class="p">().</span><span class="nf">nonzero</span><span class="p">().</span><span class="nf">t</span><span class="p">().</span><span class="nf">contiguous</span><span class="p">()</span>
            <span class="n">lifted_topology</span><span class="p">[</span><span class="sa">f</span><span class="sh">'</span><span class="s">incidence_</span><span class="si">{</span><span class="n">r</span><span class="si">}</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">lifted_topology</span><span class="p">[</span><span class="sa">f</span><span class="sh">'</span><span class="s">incidence_</span><span class="si">{</span><span class="n">r</span><span class="si">}</span><span class="sh">'</span><span class="p">].</span><span class="nf">to_dense</span><span class="p">().</span><span class="nf">nonzero</span><span class="p">().</span><span class="nf">t</span><span class="p">().</span><span class="nf">contiguous</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">simplicial_complex</span><span class="p">.</span><span class="n">dim</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">lifted_topology</span><span class="p">[</span><span class="sa">f</span><span class="sh">'</span><span class="s">x_idx_</span><span class="si">{</span><span class="n">r</span><span class="si">}</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">simplicial_complex</span><span class="p">.</span><span class="nf">skeleton</span><span class="p">(</span><span class="n">r</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">int</span><span class="p">)</span>

        <span class="n">lifted_topology</span><span class="p">[</span><span class="sh">"</span><span class="s">x_0</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">(</span>
            <span class="nf">list</span><span class="p">(</span><span class="n">simplicial_complex</span><span class="p">.</span><span class="nf">get_simplex_attributes</span><span class="p">(</span><span class="sh">"</span><span class="s">features</span><span class="sh">"</span><span class="p">,</span> <span class="mi">0</span><span class="p">).</span><span class="nf">values</span><span class="p">())</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">lifted_topology</span>
   <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">torch_geometric</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Data</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch_geometric</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Data</span><span class="p">:</span>
        <span class="n">initial_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="nf">to_dict</span><span class="p">()</span>
        <span class="n">lifted_topology</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">lift_topology</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">lifted_topology</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">feature_lifting</span><span class="p">(</span><span class="n">lifted_topology</span><span class="p">)</span>
        <span class="k">return</span> <span class="nc">SimplexData</span><span class="p">(</span><span class="o">**</span><span class="n">initial_data</span><span class="p">,</span> <span class="o">**</span><span class="n">lifted_topology</span><span class="p">)</span></code></pre></figure>

<p>The only thing missing is to define our prefered <code class="language-plaintext highlighter-rouge">feature_lifting</code>.</p>

<h2 id="giving-meaning-to-structure">Giving meaning to structure</h2>

<p>Now that we have a higher-order topological space, there is only one thing we are missing. <em>What should the embeddings of the \(r\)-simplex higher than \(0\) be ?</em></p>

<p>Authors in <d-cite key="eijkelboom2023n"></d-cite> perform an element-wise mean of the components of lower \(r\)-simplex, however other alternative are also experimentally tried. The following definition comes in place of the <code class="language-plaintext highlighter-rouge">lift_features</code> as can be found in the example <code class="language-plaintext highlighter-rouge">ProjectionSum</code>.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">lift_features</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">torch_geometric</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Data</span> <span class="o">|</span> <span class="nb">dict</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch_geometric</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Data</span> <span class="o">|</span> <span class="nb">dict</span><span class="p">:</span>
        <span class="n">max_dim</span> <span class="o">=</span> <span class="nf">max</span><span class="p">([</span><span class="nf">int</span><span class="p">(</span><span class="n">key</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s">_</span><span class="sh">"</span><span class="p">)[</span><span class="mi">1</span><span class="p">])</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">data</span><span class="p">.</span><span class="nf">keys</span><span class="p">()</span> <span class="k">if</span> <span class="sh">"</span><span class="s">incidence</span><span class="sh">"</span> <span class="ow">in</span> <span class="n">key</span><span class="p">])</span>


        <span class="n">simplex_test_dict</span> <span class="o">=</span> <span class="nf">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">max_dim</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">z</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="c1"># For the k-component point in the i-simplices where k &lt;= i
</span>            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
                <span class="c1"># Get the k-node indices of the i-simplices (i.e. the k-components of the i-simplices)
</span>                <span class="n">z_i_idx</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="sa">f</span><span class="sh">'</span><span class="s">x_idx_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="sh">'</span><span class="p">][:,</span> <span class="n">k</span><span class="p">]</span>
                <span class="c1"># Get the node embeddings for the k-components of the i-simplices
</span>                <span class="n">z_i</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="sh">'</span><span class="s">x_0</span><span class="sh">'</span><span class="p">][</span><span class="n">z_i_idx</span><span class="p">]</span>
                <span class="n">z</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">z_i</span><span class="p">)</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
            <span class="c1"># Mean along the simplex dimension
</span>            <span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
            <span class="c1"># Assign to each i-simplex the corresponding feature
</span>            <span class="k">for</span> <span class="n">l</span><span class="p">,</span> <span class="n">embedding</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
                <span class="n">simplex_test_dict</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">append</span><span class="p">(</span><span class="n">z</span><span class="p">[</span><span class="n">l</span><span class="p">])</span>

        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">simplex_test_dict</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
            <span class="n">data</span><span class="p">[</span><span class="sa">f</span><span class="sh">'</span><span class="s">x_</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">data</span></code></pre></figure>

<p>Below is a visualization of the embedding process.</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        

<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/2024-06-30-smpn/simplex_features-480.webp 480w,/assets/img/2024-06-30-smpn/simplex_features-800.webp 800w,/assets/img/2024-06-30-smpn/simplex_features-1400.webp 1400w," sizes="95vw" type="image/webp"></source>
    
    <img src="/assets/img/2024-06-30-smpn/simplex_features.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

    </div>
</div>

<h2 id="the-network">The network</h2>
<p>An overall image is presented here</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        

<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/2024-06-30-smpn/arch-480.webp 480w,/assets/img/2024-06-30-smpn/arch-800.webp 800w,/assets/img/2024-06-30-smpn/arch-1400.webp 1400w," sizes="95vw" type="image/webp"></source>
    
    <img src="/assets/img/2024-06-30-smpn/arch.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

    </div>
</div>

<h3 id="defining-a-layer">Defining a layer</h3>

<p>We are using the definitions we stated previously and setting a convolutional kernel for the two types of communication: 1) \(r\)-simplex to \(r\)-simplex and \((r-1)\)-simplex to \(r\)-simplex. They will come to be named <code class="language-plaintext highlighter-rouge">convs_same_rank</code> and <code class="language-plaintext highlighter-rouge">convs_low_to_high</code>.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">channels</span><span class="p">,</span>
        <span class="n">max_rank</span><span class="p">,</span>
        <span class="n">n_inv</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]],</span> <span class="c1"># Number of invariances from r-simplex to r-simplex
</span>        <span class="n">aggr_func</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="sh">"</span><span class="s">mean</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">sum</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="sh">"</span><span class="s">sum</span><span class="sh">"</span><span class="p">,</span>
        <span class="n">update_func</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="sh">"</span><span class="s">relu</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">sigmoid</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">tanh</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">silu</span><span class="sh">"</span><span class="p">]</span> <span class="o">|</span> <span class="bp">None</span> <span class="o">=</span> <span class="sh">"</span><span class="s">sigmoid</span><span class="sh">"</span><span class="p">,</span>
        <span class="n">aggr_update_func</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="sh">"</span><span class="s">relu</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">sigmoid</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">tanh</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">silu</span><span class="sh">"</span><span class="p">]</span> <span class="o">|</span> <span class="bp">None</span> <span class="o">=</span> <span class="sh">"</span><span class="s">sigmoid</span><span class="sh">"</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">channels</span> <span class="o">=</span> <span class="n">channels</span>
        <span class="n">self</span><span class="p">.</span><span class="n">max_rank</span> <span class="o">=</span> <span class="n">max_rank</span>
        
        <span class="c1"># convolutions within the same rank
</span>        <span class="n">self</span><span class="p">.</span><span class="n">convs_same_rank</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">ModuleDict</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="sa">f</span><span class="sh">"</span><span class="s">rank_</span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="sh">"</span><span class="p">:</span> 
                    <span class="nc">EConv</span><span class="p">(</span>
                        <span class="n">in_channels</span><span class="o">=</span><span class="n">channels</span><span class="p">,</span>
                        <span class="n">weight_channels</span><span class="o">=</span><span class="n">n_inv</span><span class="p">[</span><span class="sa">f</span><span class="sh">"</span><span class="s">rank_</span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="sh">"</span><span class="p">][</span><span class="sa">f</span><span class="sh">"</span><span class="s">rank_</span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="sh">"</span><span class="p">],</span> <span class="c1">#from r-simplex to r-simplex
</span>                        <span class="n">out_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">with_linear_transform_1</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                        <span class="n">with_linear_transform_2</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                        <span class="n">with_weighted_message</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                        <span class="n">update_func</span><span class="o">=</span><span class="n">update_func</span><span class="p">,</span>
                    <span class="p">)</span>

                <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">max_rank</span><span class="p">)</span> <span class="c1"># Same rank conv up to r-1
</span>            <span class="p">}</span>
        <span class="p">)</span>

        <span class="c1"># convolutions from lower to higher rank
</span>        <span class="n">self</span><span class="p">.</span><span class="n">convs_low_to_high</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">ModuleDict</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="sa">f</span><span class="sh">"</span><span class="s">rank_</span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="sh">"</span><span class="p">:</span> 
                    <span class="nc">EConv</span><span class="p">(</span>
                        <span class="n">in_channels</span><span class="o">=</span><span class="n">channels</span><span class="p">,</span>
                        <span class="n">weight_channels</span><span class="o">=</span><span class="n">n_inv</span><span class="p">[</span><span class="sa">f</span><span class="sh">"</span><span class="s">rank_</span><span class="si">{</span><span class="n">rank</span><span class="o">-</span><span class="mi">1</span><span class="si">}</span><span class="sh">"</span><span class="p">][</span><span class="sa">f</span><span class="sh">"</span><span class="s">rank_</span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="sh">"</span><span class="p">],</span> <span class="c1">#from r-1-simplex to r-simplex
</span>                        <span class="n">out_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">with_linear_transform_1</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                        <span class="n">with_linear_transform_2</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                        <span class="n">with_weighted_message</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                        <span class="n">update_func</span><span class="o">=</span><span class="n">update_func</span><span class="p">,</span>
                    <span class="p">)</span>

                <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_rank</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
            <span class="p">}</span>
        <span class="p">)</span>
        <span class="c1"># aggregation functions
</span>        <span class="n">self</span><span class="p">.</span><span class="n">scatter_aggregations</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">ModuleDict</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="sa">f</span><span class="sh">"</span><span class="s">rank_</span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="sh">"</span><span class="p">:</span> <span class="nc">ScatterAggregation</span><span class="p">(</span>
                    <span class="n">aggr_func</span><span class="o">=</span><span class="n">aggr_func</span><span class="p">,</span> 
                    <span class="n">update_func</span><span class="o">=</span><span class="n">aggr_update_func</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">max_rank</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="p">}</span>
        <span class="p">)</span></code></pre></figure>

<p>Finally, we define \(\phi_m\) which will be the MLP over the message update.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python">        <span class="c1"># Perform an update over the received
</span>        <span class="c1"># messages by each other layer
</span>        <span class="n">self</span><span class="p">.</span><span class="n">update</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">ModuleDict</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">max_rank</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">factor</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="k">for</span> <span class="n">target_dict</span> <span class="ow">in</span> <span class="n">n_inv</span><span class="p">.</span><span class="nf">values</span><span class="p">():</span>
                <span class="k">for</span> <span class="n">target_rank</span> <span class="ow">in</span> <span class="n">target_dict</span><span class="p">.</span><span class="nf">keys</span><span class="p">():</span>
                    <span class="n">factor</span> <span class="o">+=</span> <span class="nf">int</span><span class="p">(</span><span class="n">target_rank</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="nf">str</span><span class="p">(</span><span class="n">rank</span><span class="p">))</span>
            <span class="n">self</span><span class="p">.</span><span class="n">update</span><span class="p">[</span><span class="sa">f</span><span class="sh">"</span><span class="s">rank_</span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span>
                <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">factor</span><span class="o">*</span><span class="n">channels</span><span class="p">,</span> <span class="n">channels</span><span class="p">),</span>
                <span class="n">nn</span><span class="p">.</span><span class="nc">SiLU</span><span class="p">(),</span>
                <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="n">channels</span><span class="p">)</span>
                <span class="p">)</span></code></pre></figure>

<p>Now, on the forward pass. We will receive information of features, incidences, adjacencies and the invariances for both of these relationships as well. The steps are the following</p>

<ul>
  <li>Same rank convolutions, where we build a message</li>
  <li>Low to high rank convolutions</li>
  <li>Concat the embeddings for the \(r\)-simplex that have received messages from different hierarchies</li>
  <li>Pass the embeddings over \(\phi_m\)</li>
  <li>Add residual connections</li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">adjacencies</span><span class="p">,</span> <span class="n">incidences</span><span class="p">,</span> <span class="n">invariances_r_r</span><span class="p">,</span> <span class="n">invariances_r_r_minus_1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
        <span class="k">for</span> <span class="n">rank</span><span class="p">,</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">features</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
            <span class="nf">assert</span><span class="p">(</span><span class="ow">not</span> <span class="n">torch</span><span class="p">.</span><span class="nf">isnan</span><span class="p">(</span><span class="n">feature</span><span class="p">).</span><span class="nf">any</span><span class="p">())</span>
            <span class="nf">assert</span><span class="p">(</span><span class="ow">not</span> <span class="n">torch</span><span class="p">.</span><span class="nf">isinf</span><span class="p">(</span><span class="n">feature</span><span class="p">).</span><span class="nf">any</span><span class="p">())</span>
        <span class="n">aggregation_dict</span> <span class="o">=</span> <span class="p">{}</span> 

        <span class="n">h</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="c1"># Same rank convolutions
</span>        <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">max_rank</span><span class="p">):</span>
            <span class="c1"># Get the convolution operation for the same rank
</span>            <span class="n">conv</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">convs_same_rank</span><span class="p">[</span><span class="sa">f</span><span class="sh">"</span><span class="s">rank_</span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="sh">"</span><span class="p">]</span>

            <span class="n">rank_str</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"</span><span class="s">rank_</span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="sh">"</span>
            <span class="n">x_source</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="n">rank_str</span><span class="p">]</span>
            <span class="n">x_target</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="n">rank_str</span><span class="p">]</span>

            <span class="n">edge_index</span> <span class="o">=</span> <span class="n">adjacencies</span><span class="p">[</span><span class="n">rank_str</span><span class="p">]</span>
            <span class="n">x_weights</span> <span class="o">=</span> <span class="n">invariances_r_r</span><span class="p">[</span><span class="n">rank_str</span><span class="p">]</span>

            <span class="c1"># print(rank, x_source.size(), x_target.size(), x_weights.size(), edge_index.size())
</span>
            <span class="n">send_idx</span><span class="p">,</span> <span class="n">recv_idx</span> <span class="o">=</span> <span class="n">edge_index</span>

            <span class="c1"># Run the convolution
</span>            <span class="n">message</span> <span class="o">=</span> <span class="nf">conv</span><span class="p">(</span><span class="n">x_source</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">,</span> <span class="n">x_weights</span><span class="p">,</span> <span class="n">x_target</span><span class="p">)</span>

            <span class="nf">assert</span><span class="p">(</span><span class="n">message</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">==</span> <span class="n">recv_idx</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
            <span class="nf">assert</span><span class="p">(</span><span class="ow">not</span> <span class="n">torch</span><span class="p">.</span><span class="nf">isnan</span><span class="p">(</span><span class="n">message</span><span class="p">).</span><span class="nf">any</span><span class="p">())</span>
            <span class="nf">assert</span><span class="p">(</span><span class="ow">not</span> <span class="n">torch</span><span class="p">.</span><span class="nf">isinf</span><span class="p">(</span><span class="n">message</span><span class="p">).</span><span class="nf">any</span><span class="p">())</span>

            <span class="n">message_aggr</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">scatter_aggregations</span><span class="p">[</span><span class="n">rank_str</span><span class="p">](</span><span class="n">message</span><span class="p">,</span> <span class="n">recv_idx</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">target_dim</span><span class="o">=</span><span class="n">x_target</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

            <span class="n">aggregation_dict</span><span class="p">[</span><span class="n">rank_str</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
                <span class="sh">"</span><span class="s">message</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span><span class="n">message_aggr</span><span class="p">],</span>
                <span class="sh">"</span><span class="s">recv_idx</span><span class="sh">"</span><span class="p">:</span> <span class="n">recv_idx</span><span class="p">,</span>
            <span class="p">}</span>

        <span class="c1"># Low to high convolutions starting from rank 1 and looking
</span>        <span class="c1"># backward to convolute
</span>        <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">max_rank</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">conv</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">convs_low_to_high</span><span class="p">[</span><span class="sa">f</span><span class="sh">"</span><span class="s">rank_</span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="sh">"</span><span class="p">]</span>

            <span class="n">rank_str</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"</span><span class="s">rank_</span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="sh">"</span>
            <span class="n">rank_minus_1_str</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"</span><span class="s">rank_</span><span class="si">{</span><span class="n">rank</span><span class="o">-</span><span class="mi">1</span><span class="si">}</span><span class="sh">"</span>

            <span class="n">x_source</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="n">rank_minus_1_str</span><span class="p">]</span>
            <span class="n">x_target</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="n">rank_str</span><span class="p">]</span>
            <span class="n">x_weights</span> <span class="o">=</span> <span class="n">invariances_r_r_minus_1</span><span class="p">[</span><span class="n">rank_str</span><span class="p">]</span>
            <span class="n">edge_index</span> <span class="o">=</span> <span class="n">incidences</span><span class="p">[</span><span class="n">rank_str</span><span class="p">]</span>

            <span class="n">send_idx</span><span class="p">,</span> <span class="n">recv_idx</span> <span class="o">=</span> <span class="n">edge_index</span>

            <span class="c1"># Run the convolution
</span>            <span class="n">message</span> <span class="o">=</span> <span class="nf">conv</span><span class="p">(</span><span class="n">x_source</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">,</span> <span class="n">x_weights</span><span class="p">,</span> <span class="n">x_target</span><span class="p">)</span>
            <span class="n">message_aggr</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">scatter_aggregations</span><span class="p">[</span><span class="n">rank_str</span><span class="p">](</span><span class="n">message</span><span class="p">,</span> <span class="n">recv_idx</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">target_dim</span><span class="o">=</span><span class="n">x_target</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

            <span class="nf">assert</span><span class="p">(</span><span class="n">message</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">==</span> <span class="n">recv_idx</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>

            <span class="c1"># Aggregate the message
</span>            <span class="k">if</span> <span class="n">rank_str</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">aggregation_dict</span><span class="p">:</span>
                <span class="n">aggregation_dict</span><span class="p">[</span><span class="n">rank_str</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="sh">"</span><span class="s">message</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span><span class="n">message_aggr</span><span class="p">],</span>
                    <span class="sh">"</span><span class="s">recv_idx</span><span class="sh">"</span><span class="p">:</span> <span class="n">recv_idx</span><span class="p">,</span>
                <span class="p">}</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">aggregation_dict</span><span class="p">[</span><span class="n">rank_str</span><span class="p">][</span><span class="sh">'</span><span class="s">message</span><span class="sh">'</span><span class="p">].</span><span class="nf">append</span><span class="p">(</span><span class="n">message_aggr</span><span class="p">)</span> 
                <span class="sh">'''</span><span class="s">
                aggregation_dict[rank_str] = {
                    </span><span class="sh">"</span><span class="s">message</span><span class="sh">"</span><span class="s">: [prev_msg, message],
                    #</span><span class="sh">"</span><span class="s">recv_idx</span><span class="sh">"</span><span class="s">: torch.cat((aggregation_dict[rank][</span><span class="sh">"</span><span class="s">recv_idx</span><span class="sh">"</span><span class="s">], recv_idx)),
                    for prev_msg in aggregation_dict[rank_str][</span><span class="sh">"</span><span class="s">message</span><span class="sh">"</span><span class="s">]
                }
                </span><span class="sh">'''</span>

        <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">max_rank</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
            <span class="c1"># Check for ranks not receiving any messages
</span>            <span class="n">rank_str</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"</span><span class="s">rank_</span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="sh">"</span>
            <span class="k">if</span> <span class="n">rank_str</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">aggregation_dict</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">message</span> <span class="o">=</span> <span class="n">aggregation_dict</span><span class="p">[</span><span class="n">rank_str</span><span class="p">][</span><span class="sh">"</span><span class="s">message</span><span class="sh">"</span><span class="p">]</span>
            <span class="n">recv_idx</span> <span class="o">=</span> <span class="n">aggregation_dict</span><span class="p">[</span><span class="n">rank_str</span><span class="p">][</span><span class="sh">"</span><span class="s">recv_idx</span><span class="sh">"</span><span class="p">]</span>
            <span class="n">x_target</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="n">rank_str</span><span class="p">]</span>

            <span class="c1"># Aggregate the message
</span>            <span class="c1">#h[rank_str] = self.scatter_aggregations[rank_str](message, recv_idx, dim=0, target_dim=x_target.shape[0])
</span>
        <span class="c1"># Update over the final embeddings with another MLP
</span>
        <span class="n">h</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">rank</span><span class="p">,</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">features</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
            <span class="n">feat_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">feature</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">msg_i</span> <span class="ow">in</span> <span class="n">aggregation_dict</span><span class="p">[</span><span class="n">rank</span><span class="p">][</span><span class="sh">"</span><span class="s">message</span><span class="sh">"</span><span class="p">]:</span>
                <span class="n">feat_list</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">msg_i</span><span class="p">)</span>
            <span class="n">h</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">(</span><span class="n">feat_list</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">h</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">rank</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="n">update</span><span class="p">[</span><span class="n">rank</span><span class="p">](</span><span class="n">feature</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">rank</span><span class="p">,</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">h</span><span class="p">.</span><span class="nf">items</span><span class="p">()</span>
        <span class="p">}</span>

        <span class="c1"># Residual connection
</span>        <span class="n">x</span> <span class="o">=</span> <span class="p">{</span><span class="n">rank</span><span class="p">:</span> <span class="n">feature</span> <span class="o">+</span> <span class="n">h</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="k">for</span> <span class="n">rank</span><span class="p">,</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">features</span><span class="p">.</span><span class="nf">items</span><span class="p">()}</span>

        <span class="k">return</span> <span class="n">x</span></code></pre></figure>

<h3 id="all-together">All together</h3>

<p>Piecing it all together, our modules look like this.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">max_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">inv_dims</span><span class="p">:</span> <span class="n">Dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span> 
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>

        <span class="n">self</span><span class="p">.</span><span class="n">max_dim</span> <span class="o">=</span> <span class="n">max_dim</span>
        <span class="n">self</span><span class="p">.</span><span class="n">feature_embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">ModuleList</span><span class="p">(</span>
            <span class="p">[</span><span class="nc">EMPSNLayer</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">max_dim</span><span class="p">,</span> <span class="n">aggr_func</span><span class="o">=</span><span class="sh">"</span><span class="s">sum</span><span class="sh">"</span><span class="p">,</span> <span class="n">update_func</span><span class="o">=</span><span class="sh">"</span><span class="s">silu</span><span class="sh">"</span><span class="p">,</span> <span class="n">aggr_update_func</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">n_inv</span><span class="o">=</span><span class="n">inv_dims</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n_layers</span><span class="p">)]</span>
        <span class="p">)</span>

        <span class="c1"># Pre-pooling operation
</span>        <span class="n">self</span><span class="p">.</span><span class="n">pre_pool</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">ModuleDict</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">max_dim</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">self</span><span class="p">.</span><span class="n">pre_pool</span><span class="p">[</span><span class="sa">f</span><span class="sh">"</span><span class="s">rank_</span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="sh">"</span><span class="p">]</span><span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span>
                <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">),</span>
                <span class="n">nn</span><span class="p">.</span><span class="nc">SiLU</span><span class="p">(),</span>
                <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="c1"># Post-pooling operation over all dimensions
</span>        <span class="c1"># and final classification
</span>        <span class="n">self</span><span class="p">.</span><span class="n">post_pool</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">((</span><span class="n">max_dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">hidden_channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">SiLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">)</span>
        <span class="p">)</span></code></pre></figure>

<p>In the first line we call <code class="language-plaintext highlighter-rouge">decompose_batch</code> which grabs the batch object and returns the features, the adjacencies and also calculates the invariances for a given batch. Then we proceed running through the network.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span><span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="n">features</span><span class="p">,</span> <span class="n">edge_index_adj</span><span class="p">,</span> <span class="n">edge_index_inc</span><span class="p">,</span> <span class="n">inv_r_r</span><span class="p">,</span> <span class="n">inv_r_minus_1_r</span><span class="p">,</span> <span class="n">x_batch</span> <span class="o">=</span> <span class="nf">decompose_batch</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">max_dim</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">rank</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="nf">feature_embedding</span><span class="p">(</span><span class="n">feature</span><span class="p">)</span> 
            <span class="k">for</span> <span class="n">rank</span><span class="p">,</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">features</span><span class="p">.</span><span class="nf">items</span><span class="p">()</span>
        <span class="p">}</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="nf">layer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index_adj</span><span class="p">,</span> <span class="n">edge_index_inc</span><span class="p">,</span> <span class="n">inv_r_r</span><span class="p">,</span> <span class="n">inv_r_minus_1_r</span><span class="p">)</span>

        <span class="c1"># read out
</span>        <span class="n">x</span> <span class="o">=</span> <span class="p">{</span><span class="n">rank</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="n">pre_pool</span><span class="p">[</span><span class="n">rank</span><span class="p">](</span><span class="n">feature</span><span class="p">)</span> <span class="k">for</span> <span class="n">rank</span><span class="p">,</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">x</span><span class="p">.</span><span class="nf">items</span><span class="p">()}</span>
        <span class="n">x</span> <span class="o">=</span> <span class="p">{</span><span class="n">rank</span><span class="p">:</span> <span class="nf">global_add_pool</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">rank</span><span class="p">],</span> <span class="n">batch</span><span class="o">=</span><span class="n">x_batch</span><span class="p">[</span><span class="n">rank</span><span class="p">])</span> <span class="k">for</span> <span class="n">rank</span><span class="p">,</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">x</span><span class="p">.</span><span class="nf">items</span><span class="p">()}</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">(</span><span class="nf">tuple</span><span class="p">([</span><span class="n">feature</span> <span class="k">for</span> <span class="n">rank</span><span class="p">,</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">x</span><span class="p">.</span><span class="nf">items</span><span class="p">()]),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">post_pool</span><span class="p">(</span><span class="n">state</span><span class="p">)</span> <span class="c1"># Classifier across 19 variables 
</span>        <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">squeeze</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span></code></pre></figure>

<h1 id="experiments">Experiments</h1>

<p>We performed the experiments using both the Alpha Complex Lifting and the Vietoris-Rips Complex Lifting. The figure below show the MAE for validation and training on a random subsample of 1000 molecules. The figure below shows that the overall performance of the Alpha Complex is lower that the Vietoris-Rips complex for this task. We assume this is likely due to the fact that Alpha complex creates fewer (higher order) simplices, which might lead to a worse outcome, especially on this dataset.</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        

<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/2024-06-30-smpn/train_mae_topox-480.webp 480w,/assets/img/2024-06-30-smpn/train_mae_topox-800.webp 800w,/assets/img/2024-06-30-smpn/train_mae_topox-1400.webp 1400w," sizes="95vw" type="image/webp"></source>
    
    <img src="/assets/img/2024-06-30-smpn/train_mae_topox.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

    </div>
</div>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        

<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/2024-06-30-smpn/validation_mae_topox-480.webp 480w,/assets/img/2024-06-30-smpn/validation_mae_topox-800.webp 800w,/assets/img/2024-06-30-smpn/validation_mae_topox-1400.webp 1400w," sizes="95vw" type="image/webp"></source>
    
    <img src="/assets/img/2024-06-30-smpn/validation_mae_topox.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

    </div>
</div>

<h1 id="conclusions">Conclusions</h1>

<p>In this post, we have investigated the novel development suite for Topological Deep Learning and how it can be used to tackle a particular problem. We go over concepts in <strong>geometric deep learning</strong> and show why they work and how can we leverage topological representations to better learn in message passing networks. The usage of the unified TopoX framework allows for ease of development and standarization in regards of the reproducibility. As this framework grows, ease of development in TDL should follow. Additionally, we the work of <d-cite key="eijkelboom2023n"></d-cite> and explore the performance on the Alpha Complex. Given the computing limitations for executing these models, our experiments fall short of complete. However, it remains useful to further explore ways in which to optimize this models, given the pontential expressivity they achieve.</p>


      </d-article>

      <d-appendix>
        <d-footnote-list></d-footnote-list>
        <d-citation-list></d-citation-list>
      </d-appendix>

      <d-bibliography src="/assets/bibliography/2024-06-30-smpn.bib"></d-bibliography>

      
      
    </div>

    <!-- Footer -->
    
  <footer class="sticky-bottom mt-5" role="contentinfo">
    <div class="container">
      Â© Copyright 2024
      
      
      . 
      
      
    </div>
  </footer>


    <!-- Bootsrap & MDB scripts -->
<script src="/assets/js/bootstrap.bundle.min.js"></script>
<!-- <script src="/assets/js/mdb.min.js"></script> -->
<script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    


    
  <!-- Scrolling Progress Bar -->
  <script type="text/javascript">
    /*
     * This JavaScript code has been adapted from the article
     * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar,
     * published on the website https://css-tricks.com on the 7th of May, 2014.
     * Couple of changes were made to the original code to make it compatible
     * with the `al-foio` theme.
     */
    const progressBar = $('#progress');
    /*
     * We set up the bar after all elements are done loading.
     * In some cases, if the images in the page are larger than the intended
     * size they'll have on the page, they'll be resized via CSS to accomodate
     * the desired size. This mistake, however, breaks the computations as the
     * scroll size is computed as soon as the elements finish loading.
     * To account for this, a minimal delay was introduced before computing the
     * values.
     */
    window.onload = function () {
      setTimeout(progressBarSetup, 50);
    };
    /*
     * We set up the bar according to the browser.
     * If the browser supports the progress element we use that.
     * Otherwise, we resize the bar thru CSS styling
     */
    function progressBarSetup() {
      if ('max' in document.createElement('progress')) {
        initializeProgressElement();
        $(document).on('scroll', function () {
          progressBar.attr({ value: getCurrentScrollPosition() });
        });
        $(window).on('resize', initializeProgressElement);
      } else {
        resizeProgressBar();
        $(document).on('scroll', resizeProgressBar);
        $(window).on('resize', resizeProgressBar);
      }
    }
    /*
     * The vertical scroll position is the same as the number of pixels that
     * are hidden from view above the scrollable area. Thus, a value > 0 is
     * how much the user has scrolled from the top
     */
    function getCurrentScrollPosition() {
      return $(window).scrollTop();
    }

    function initializeProgressElement() {
      let navbarHeight = $('#navbar').outerHeight(true);
      $('body').css({ 'padding-top': navbarHeight });
      $('progress-container').css({ 'padding-top': navbarHeight });
      progressBar.css({ top: navbarHeight });
      progressBar.attr({
        max: getDistanceToScroll(),
        value: getCurrentScrollPosition(),
      });
    }
    /*
     * The offset between the html document height and the browser viewport
     * height will be greater than zero if vertical scroll is possible.
     * This is the distance the user can scroll
     */
    function getDistanceToScroll() {
      return $(document).height() - $(window).height();
    }

    function resizeProgressBar() {
      progressBar.css({ width: getWidthPercentage() + '%' });
    }
    // The scroll ratio equals the percentage to resize the bar
    function getWidthPercentage() {
      return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
    }
  </script>


  
</body>
</html>
